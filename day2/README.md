# homework1

## 実装

### delete機能を実装
- **先頭要素の削除**  
  `self.buckets[bucket_index] = item.next`でバケットの先頭を更新

- **中間・末尾要素の削除**  
  `prev.next = item.next`で前の要素と次の要素を接続

- **要素が存在しない場合**  
  `False`を返して削除失敗を通知



### 再ハッシュ関数を追加

- **拡大条件**：使用率が70%以上の場合、サイズを2倍+1に拡大
- **縮小条件**：使用率が30%未満の場合、サイズを半分に縮小（最小97は維持）
- **無限ループ防止**：リハッシュ中は再帰的リハッシュにならないよう実装

疑問：70%、30%のところはどこで計算実行するのが一番良いか？
### hash値の計算を、衝突が少なくなるように改善
素数を用いて、桁数に応じて重み付けすればいいのではないか  
↓  
衝突は減るが、値と素数によってはアナグラム問題が解決されない  
↓  
位置による重み付け+ローリングハッシュを採用  
- 31の部分は他の素数でも良いのかと思っていたが、31が経験則的に良いらしい    
- 0xFFFFFFFFで32ビット制限をかけることで計算効率およびメモリ効率を改善  


## 再ハッシュの効果

| イテレーション | 再ハッシュなし (秒) | 再ハッシュあり (秒) | 改善率 |
|:------------:|:------------------:|:-----------------:|:-----:|
| 0 | 0.189091 | 0.165683 | 1.14x |
| 10 | 2.751768 | 0.097865 | 28.1x |
| 20 | 8.971665 | 0.152655 | 58.8x |
| 30 | 14.808546 | 0.099297 | 149.1x |
| 40 | 20.026890 | 0.098274 | 203.8x |
| 50 | 19.243019 | 0.100279 | 191.9x |
| 60 | - | 0.101702 | - |
| 70 | - | 0.097911 | - |
| 80 | - | 0.100595 | - |
| 90 | - | 0.101465 | - |
| 99 | - | 0.472530 | - |

## 性能

|  | 再ハッシュなし | 再ハッシュあり |
|:-----|:-------------|:-------------|
| **初期性能** | 約0.19秒 | 約0.17秒 |
| **50回目の性能** | 約19秒 | 約0.1秒 |
| **平均計算量** | O(n) | O(1) |
| **最悪計算量** | O(n) | O(n) |
| **空間計算量** | O(n) | O(n) |







# homework2
## 実際の大規模データベースにおいてハッシュテーブルより木構造が適している理由
### ハッシュテーブルだと
- 大規模だと異なるキーが同じハッシュ値をもつ可能性が高く、その分衝突が起きやすい
- 再ハッシュが必要になった際に、テーブルの全要素を入れ替える必要がある
- ハッシュ値で管理されているため空の領域が存在する可能性が高く、メモリ効率が悪い
- ハッシュ値の順序が本質的な意味を持たないため、部分的な操作が困難

### 木構造だと
- 必要な要素の分だけメモリを消費するため、メモリ効率が良い
- 構造的に順序関係を反映されているため、部分的な操作が効率的


# homework3
キャッシュの計算がO(1)でできる、もっとも直近にアクセスされた上位 X 個の <URL, Web ページ> の組が保存できるデータ構造を考える

ハッシュテーブルと連結リストを組み合わせると良いのでは？

ハッシュテーブル：検索がO(1)  
連結リスト：順序を格納


# homework4

## アルゴリズム

### データ構造
- 前のノードと次のノードの両方を持つ双方向連結リストを使用
- O(1)でのURL探索が可能なハッシュテーブルを使用

### 操作
- 既存ページ : 連結リストから削除後、一番前に移動
- 新規ページ : 容量をチェック後、一番前に追加
- 容量超過時 : 一番古いページを削除

### 計算量
- 時間計算量：O(1)
- 空間計算量：O(n)

## 実行方法

```
python cache.py
```

## 工夫した点
- ダミーノードを使用し、ハッシュテーブルの要素の個数での場合分けをなくした





# メモ

## ハッシュテーブルと木構造について
ハッシュテーブルが大規模だと異なるキーが同じハッシュ値をもつ可能性が高く、その分衝突が起きやすい
- ハッシュテーブルのサイズを大きくして適切なハッシュ関数を用いれば、偏りすぎるということはない
- どちらかというと最悪ケースの話
- 木構造でも、根本がホットスポットになるという点では偏っている

ハッシュテーブルだと再ハッシュが必要になった際に、テーブルの全要素を入れ替える必要がある
- Googleも、amazonも、facebookもlmsデータ構造
- キャッシュについては、基本的にgoogleもlruを採用





## なぜ、双方向連結リストなのか？
- ハッシュテーブルで値を見つけても、単方向連結リストだと次のポインタしか持たないため、追加・検索・削除の操作をする際に連結リストの一番最初から辿る必要がある
- そのほかの選択肢として、ベクトルなどがあるが、




## レビュー
- トライ木 pdb3 
